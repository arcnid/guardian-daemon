package main

import (
	"encoding/json"
	"errors"
	"fmt"
	"log"
	"net/http"
	"os"
	"os/signal"
	"strconv"
	"strings"
	"sync"
	"syscall"
	"time"

	mqtt "github.com/eclipse/paho.mqtt.golang"
	"github.com/joho/godotenv"
	"github.com/nedpals/supabase-go"

	// Import the Expo push notification SDK
	expo "github.com/oliveroneill/exponent-server-sdk-golang/sdk"
)

// DeviceLog represents the structure of an device log entry
type DeviceLog struct {
	ID                 string     `json:"id"`                   // UUID, auto-generated by Supabase
	DeviceID           string     `json:"device_id"`            // UUID
	UserID             string     `json:"user_id"`              // UUID
	CreatedAt          time.Time  `json:"created_at"`           // Timestamp
	Status             string     `json:"status"`               // e.g., "online", "offline", "error"
	TempSensorReading  *float64   `json:"temp_sensor_reading"`  // Nullable
	HumidSensorReading *float64   `json:"humid_sensor_reading"` // Nullable
	RelayState         string     `json:"relay_state"`          // e.g., "on", "off", "idle"
	DeviceType         string     `json:"device_type"`          // "relay" or "sensor"
	Metadata           *string    `json:"metadata"`             // Optional JSON metadata
}

// Task structure to represent an MQTT message
type Task struct {
	Topic   string
	Payload string
}

// Automation represents the structure of an automation rule
type Automation struct {
	ID           string     `json:"id"`
	UserID       string     `json:"user_id"`
	Type         string     `json:"action_type"` // "triggered" or "scheduled"
	LastExecuted *time.Time `json:"last_executed,omitempty"`
	LastResult   *string    `json:"last_result,omitempty"`
	Triggers     []Trigger  `json:"triggers"`
	Actions      []Action   `json:"actions"`
	Timezone     string     `json:"timezone"`
	CreatedAt    time.Time  `json:"created_at"`
	UpdatedAt    time.Time  `json:"updated_at"`
}

// Trigger represents the structure of an automation trigger
type Trigger struct {
	Type              string   `json:"type"` // "scheduled", "single_device", "two_device_diff"
	Condition         *string  `json:"condition,omitempty"`
	CommonTime        *string  `json:"common_time,omitempty"`
	DaysOfWeek        []string `json:"days_of_week,omitempty"`
	ScheduleType      *string  `json:"schedule_type,omitempty"`
	ConditionOperator *string  `json:"conditionOperator,omitempty"`
	Value             *string  `json:"value,omitempty"`
	Metric            *string  `json:"metric,omitempty"`
	DeviceID          *string  `json:"device_id,omitempty"`
	BinID             *string  `json:"bin_id,omitempty"`
	LocationID        *string  `json:"location_id,omitempty"`
	Device1           *Device  `json:"device1,omitempty"`
	Device2           *Device  `json:"device2,omitempty"`
}

// Device represents a device in a two-device trigger
type Device struct {
	BinID      string `json:"bin_id"`
	DeviceID   string `json:"device_id"`
	LocationID string `json:"location_id"`
}

// Action represents the actions executed when an automation is triggered
type Action struct {
	Type     string  `json:"type"` // "send_notification", "turn_on_relay"
	Message  *string `json:"message,omitempty"`
	DeviceID *string `json:"device_id,omitempty"`
}

// Global variables
var (
	taskQueue         = make(chan Task, 1000) // Buffered channel to hold tasks
	maxWorkers        = 20                    // Maximum number of workers
	minWorkers        = 2                     // Minimum number of workers
	workerLock        sync.Mutex              // Mutex to protect workerCount
	activeWorkers     = make(map[int]chan bool)
	workerIDCounter   = 0
	supabaseClient    *supabase.Client
	wg                sync.WaitGroup
	gracefulShutdown  = make(chan os.Signal, 1) // Channel to capture OS signals
	once              sync.Once                 // Ensures Supabase client is initialized once
	defaultDeviceID   = "default-device-id"     // Default device_id for plain text payloads
	defaultDeviceType = "relay"                 // Default device_type for plain text payloads
)

var (
	mqttClientInstance mqtt.Client
	mqttOnce           sync.Once
)

func getMQTTClient() mqtt.Client {
	mqttOnce.Do(func() {
		broker := "tcp://mosquitto:1883"
		clientID := "guardian-daemon"

		opts := mqtt.NewClientOptions().
			AddBroker(broker).
			SetClientID(clientID).
			SetDefaultPublishHandler(messageHandler)

		client := mqtt.NewClient(opts)
		if token := client.Connect(); token.Wait() && token.Error() != nil {
			log.Fatalf("Failed to connect to MQTT broker: %v", token.Error())
		}
		log.Println("Connected to MQTT broker!")
		mqttClientInstance = client
	})
	return mqttClientInstance
}

func handleSendCommand(w http.ResponseWriter, r *http.Request) {
	// Handle CORS Preflight Request
	if r.Method == http.MethodOptions {
		w.Header().Set("Access-Control-Allow-Origin", "*")
		w.Header().Set("Access-Control-Allow-Methods", "POST, OPTIONS")
		w.Header().Set("Access-Control-Allow-Headers", "Content-Type")
		w.WriteHeader(http.StatusOK)
		return
	}

	// Set CORS headers
	w.Header().Set("Access-Control-Allow-Origin", "*")
	w.Header().Set("Access-Control-Allow-Methods", "POST")
	w.Header().Set("Access-Control-Allow-Headers", "Content-Type")
	w.Header().Set("Content-Type", "application/json")

	if r.Method != http.MethodPost {
		http.Error(w, "Invalid request method. Only POST is allowed.", http.StatusMethodNotAllowed)
		return
	}

	// Parse the incoming JSON
	var message struct {
		DeviceID string                 `json:"deviceId"`
		UserID   string                 `json:"userId"`
		Data     map[string]interface{} `json:"data"`
	}

	if err := json.NewDecoder(r.Body).Decode(&message); err != nil {
		log.Printf("Error decoding request body: %v", err)
		http.Error(w, "Invalid JSON format.", http.StatusBadRequest)
		return
	}
	defer r.Body.Close()

	// Validate required fields
	if message.DeviceID == "" || message.UserID == "" || message.Data == nil {
		http.Error(w, "Missing required fields: deviceId, userId, or data.", http.StatusBadRequest)
		return
	}

	// Serialize the Data object into a JSON string
	dataJSON, err := json.Marshal(message.Data)
	if err != nil {
		log.Printf("Error serializing data to JSON: %v", err)
		http.Error(w, "Failed to serialize data to JSON.", http.StatusInternalServerError)
		return
	}

	// Construct the MQTT topic
	topic := fmt.Sprintf("/toDevice/%s/%s", message.UserID, message.DeviceID)

	// Publish the message to MQTT
	client := getMQTTClient()
	token := client.Publish(topic, 0, false, dataJSON)
	token.Wait()

	if token.Error() != nil {
		log.Printf("Failed to publish MQTT message: %v", token.Error())
		http.Error(w, "Failed to publish MQTT message.", http.StatusInternalServerError)
		return
	}

	// Respond to the client
	response := map[string]string{
		"status":  "success",
		"topic":   topic,
		"message": fmt.Sprintf("Message successfully published to topic %s", topic),
	}
	json.NewEncoder(w).Encode(response)
}

func main() {
	// Initialize Supabase client
	initSupabase()

	// Start dynamic scaling of workers
	go scheduleHandler()
	go monitorAndScaleWorkers()

	// Create the MQTT client
	client := getMQTTClient()

	// Connect to the MQTT broker
	if token := client.Subscribe("/toDaemon/#", 0, nil); token.Wait() && token.Error() != nil {
		log.Fatalf("Failed to subscribe to all topics: %v", token.Error())
	}
	log.Println("Subscribed to all topics!")

	// Handle graceful shutdown
	setupGracefulShutdown(client)

	// Init HTTP server
	http.HandleFunc("/sendComand", handleSendCommand)

	fmt.Println("Starting server on :5000...")
	err := http.ListenAndServe(":5000", nil)
	if err != nil {
		fmt.Println("Error starting server:", err)
	}

	// Keep the program running indefinitely
	select {}
}

// messageHandler handles incoming MQTT messages
func messageHandler(client mqtt.Client, msg mqtt.Message) {
	task := Task{
		Topic:   msg.Topic(),
		Payload: string(msg.Payload()),
	}

	select {
	case taskQueue <- task:
		log.Printf("Message enqueued: %s on topic %s", task.Payload, task.Topic)
		go deviceAutomationHandler(task)
	default:
		log.Printf("Task queue full. Dropping message: %s on topic %s", task.Payload, task.Topic)
	}
}

// initSupabase initializes the Supabase client as a singleton
func initSupabase() {
	once.Do(func() {
		// Load environment variables from .env file if present
		err := godotenv.Load()
		if err != nil {
			log.Println("Warning: .env file not found, falling back to system environment variables.")
		}

		supabaseURL := os.Getenv("SUPABASE_URL")
		supabaseKey := os.Getenv("SUPABASE_KEY")

		if supabaseURL == "" || supabaseKey == "" {
			log.Fatal("Supabase URL or Key not set in environment variables")
		}

		// Create Supabase client
		supabaseClient = supabase.CreateClient(supabaseURL, supabaseKey)
		log.Println("Connected to Supabase!")
	})
}

// getFloatFromPayload extracts a float64 from the payload for the given key.
func getFloatFromPayload(payload map[string]interface{}, key string) (float64, bool) {
	if val, exists := payload[key]; exists {
		switch v := val.(type) {
		case float64:
			return v, true
		case float32:
			return float64(v), true
		case int:
			return float64(v), true
		case string:
			if f, err := strconv.ParseFloat(v, 64); err == nil {
				return f, true
			}
		}
	}
	return 0, false
}

// worker processes tasks from the taskQueue
func worker(id int, stopWorkerCh chan bool) {
    log.Printf("Worker %d started", id)
    defer wg.Done()

    defer func() {
        if r := recover(); r != nil {
            log.Printf("Worker %d recovered from panic: %v", id, r)
        }
    }()

    for {
        select {
        case task := <-taskQueue:
            log.Printf("Worker %d processing task: %s on topic %s", id, task.Payload, task.Topic)
            defer func() {
                if r := recover(); r != nil {
                    log.Printf("Worker %d recovered from panic: %v", id, r)
                }
            }()
            deviceLog, err := parsePayload(task.Topic, task.Payload)
            if err != nil {
                log.Printf("Worker %d failed to parse payload: %v", id, err)
                continue
            }

            err = insertIntoSupabase(deviceLog)
            if err != nil {
                log.Printf("Worker %d failed to insert into Supabase: %v", id, err)
            }

        case <-stopWorkerCh:
            log.Printf("Worker %d stopping", id)
            return
        }
    }
}

// parsePayload parses the MQTT payload and returns a DeviceLog struct
func parsePayload(topic, payload string) (*DeviceLog, error) {
	// Attempt to parse payload as JSON
	var rawData map[string]interface{}
	err := json.Unmarshal([]byte(payload), &rawData)
	if err != nil {
		// If payload is not JSON, insert dummy data
		log.Printf("Payload is not JSON: %s. Inserting dummy data.", payload)
		return createDummyDeviceLog(topic, payload), nil
	}

	// Helper function to extract string fields
	getString := func(key string) string {
		if val, exists := rawData[key]; exists {
			if str, ok := val.(string); ok {
				return str
			}
		}
		return "" // Default to empty string if not present or not a string
	}

	// Helper function to extract float fields
	getFloat := func(key string) *float64 {
		if val, exists := rawData[key]; exists {
			switch v := val.(type) {
			case float64:
				return &v
			case float32:
				f := float64(v)
				return &f
			case int:
				f := float64(v)
				return &f
			default:
				return nil
			}
		}
		return nil // Default to nil if not present or not a number
	}

	// Extract fields with defaults
	deviceID := getString("device_id")
	userID := getString("user_id")
	status := getString("status")
	deviceType := getString("device_type")
	relayState := getString("relay_state")

	tempReading := getFloat("temp_sensor_reading")
	humidReading := getFloat("humid_sensor_reading")

	// Optional metadata field
	var metadata *string
	if val, exists := rawData["metadata"]; exists {
		if str, ok := val.(string); ok {
			metadata = &str
		}
	}

	// Validate required fields
	if deviceID == "" || userID == "" || deviceType == "" {
		return nil, errors.New("missing required fields: device_id, user_id, or device_type")
	}

	// Create the DeviceLog struct
	deviceLog := &DeviceLog{
		DeviceID:           deviceID,
		UserID:             userID,
		CreatedAt:          time.Now(),
		Status:             status,
		TempSensorReading:  tempReading,
		HumidSensorReading: humidReading,
		RelayState:         relayState,
		DeviceType:         deviceType,
		Metadata:           metadata,
	}

	return deviceLog, nil
}

// createDummyDeviceLog creates a DeviceLog with dummy data
func createDummyDeviceLog(topic, payload string) *DeviceLog {
	// Extract user_id from topic
	parts := strings.Split(topic, "/")
	userID := ""
	for i, part := range parts {
		if part == "user" && i+1 < len(parts) {
			userID = parts[i+1]
			break
		}
	}

	// If userID is not found, assign a default value
	if userID == "" {
		userID = "default-user-id"
	}

	// Assign a default device_id
	deviceID := defaultDeviceID

	// Assign default values for other fields
	status := payload               // Using the payload as status
	deviceType := defaultDeviceType // Defaulting to "relay"; adjust as needed
	relayState := "idle"            // Default relay state
	var metadata *string            // No metadata for dummy data

	return &DeviceLog{
		DeviceID:   deviceID,
		UserID:     userID,
		CreatedAt:  time.Now(),
		Status:     status,
		DeviceType: deviceType,
		RelayState: relayState,
		Metadata:   metadata,
	}
}

// insertIntoSupabase inserts a single DeviceLog into Supabase
func insertIntoSupabase(deviceLog *DeviceLog) error {
	// Convert DeviceLog to a map for insertion
	data := map[string]interface{}{
		"device_id":            deviceLog.DeviceID,
		"user_id":              deviceLog.UserID,
		"created_at":           deviceLog.CreatedAt.Format(time.RFC3339),
		"status":               deviceLog.Status,
		"temp_sensor_reading":  deviceLog.TempSensorReading,
		"humid_sensor_reading": deviceLog.HumidSensorReading,
		"relay_state":          deviceLog.RelayState,
		"device_type":          deviceLog.DeviceType,
		"metadata":             deviceLog.Metadata,
	}

	// Insert the record
	returnData := supabaseClient.DB.From("deviceLogs").Insert(data).Execute(data)

	// Log the response for debugging
	log.Printf("Supabase Insert Response: %+v", returnData)

	return nil
}

// batchInsertIntoSupabase inserts multiple DeviceLogs into Supabase in a single batch
func batchInsertIntoSupabase(deviceLogs []*DeviceLog) error {
	// Convert DeviceLogs to a slice of maps
	var data []map[string]interface{}
	for _, logEntry := range deviceLogs {
		data = append(data, map[string]interface{}{
			"device_id":            logEntry.DeviceID,
			"user_id":              logEntry.UserID,
			"created_at":           logEntry.CreatedAt.Format(time.RFC3339),
			"status":               logEntry.Status,
			"temp_sensor_reading":  logEntry.TempSensorReading,
			"humid_sensor_reading": logEntry.HumidSensorReading,
			"relay_state":          logEntry.RelayState,
			"device_type":          logEntry.DeviceType,
			"metadata":             logEntry.Metadata,
		})
	}

	// Insert the records
	returnData := supabaseClient.DB.From("deviceLogs").Insert(data).Execute(data)

	// Log the response for debugging
	log.Printf("Supabase Batch Insert Response: %+v", returnData)

	return nil
}

const (
	workerScaleThreshold   = 0.8 // 80% of maxWorkers
	queueOverloadThreshold = 0.8 // 80% of queue capacity
)

// monitorAndScaleWorkers dynamically scales the number of workers based on the taskQueue size
func monitorAndScaleWorkers() {
	for {
		queueSize := len(taskQueue)
		currentWorkers := len(activeWorkers)
		workerCapacity := float64(maxWorkers) * workerScaleThreshold
		queueCapacity := float64(cap(taskQueue)) * queueOverloadThreshold

		workerLock.Lock()

		// Log if worker count exceeds threshold
		if float64(currentWorkers) > workerCapacity {
			log.Printf("⚠️ WARNING: Worker pool is at %.0f%% capacity (%d/%d workers in use).", (float64(currentWorkers)/float64(maxWorkers))*100, currentWorkers, maxWorkers)
		}

		// Log if worker count hits max capacity
		if currentWorkers >= maxWorkers {
			log.Printf("🚨 ALERT: Worker pool has reached max capacity (%d/%d workers). Incoming tasks may experience delays.", currentWorkers, maxWorkers)
		}

		// Scale up workers if needed
		if queueSize > currentWorkers && currentWorkers < maxWorkers {
			workerIDCounter++
			newWorkerID := workerIDCounter
			stopWorkerCh := make(chan bool)
			activeWorkers[newWorkerID] = stopWorkerCh
			wg.Add(1)
			go worker(newWorkerID, stopWorkerCh)
			log.Printf("🔼 Scaled up: Started worker %d. Total workers: %d", newWorkerID, len(activeWorkers))
		}

		// Scale down workers if queue is small and above minWorkers
		if queueSize < len(activeWorkers) && len(activeWorkers) > minWorkers {
			for workerID, stopCh := range activeWorkers {
				if len(activeWorkers) > minWorkers {
					close(stopCh)
					delete(activeWorkers, workerID)
					log.Printf("🔽 Scaled down: Stopped worker %d. Total workers: %d", workerID, len(activeWorkers))
					break
				}
			}
		}

		// Log if queue is nearing capacity
		if float64(queueSize) > queueCapacity {
			log.Printf("⚠️ WARNING: Task queue is at %.0f%% capacity (%d/%d tasks in queue).", (float64(queueSize)/float64(cap(taskQueue)))*100, queueSize, cap(taskQueue))
		}

		// Log if the queue is full
		if queueSize == cap(taskQueue) {
			log.Printf("🚨 ALERT: Task queue is FULL (%d tasks). Incoming messages may be dropped.", queueSize)
		}

		workerLock.Unlock()
		time.Sleep(2 * time.Second) // Adjust scaling interval as needed
	}
}

// setupGracefulShutdown handles termination signals to shut down workers gracefully
func setupGracefulShutdown(client mqtt.Client) {
	signal.Notify(gracefulShutdown, syscall.SIGINT, syscall.SIGTERM)

	go func() {
		sig := <-gracefulShutdown
		log.Printf("Received signal: %v. Initiating shutdown...", sig)

		// Disconnect MQTT client
		client.Disconnect(250)
		log.Println("Disconnected from MQTT broker.")

		// Stop all active workers
		workerLock.Lock()
		for workerID, stopCh := range activeWorkers {
			close(stopCh)
			log.Printf("Stopped worker %d", workerID)
		}
		workerLock.Unlock()

		// Wait for all workers to finish
		wg.Wait()
		log.Println("All workers have been stopped.")

		os.Exit(0)
	}()
}

// updateAutomationLastExecuted updates the automation record's last_executed field in Supabase.
func updateAutomationLastExecuted(automationID string, ts time.Time) error {
	data := map[string]interface{}{
		"last_executed": ts.Format(time.RFC3339),
	}
	// Pass a pointer to data for Execute()
	res := supabaseClient.DB.From("user_automations").Update(data).Eq("id", automationID).Execute(&data)
	if res.Error() != "" {
		errStr := res.Error()
		log.Printf("Error updating automation %s: %v", automationID, errStr)
		return errors.New(errStr)
	}
	log.Printf("Updated automation %s with last_executed %s", automationID, ts.Format(time.RFC3339))
	return nil
}

// evaluateSensorTrigger evaluates a sensor-based trigger.
// For demonstration, this function logs the trigger details and returns false.
// In a real implementation, you would add the logic to evaluate sensor conditions.
func evaluateSensorTrigger(trigger Trigger) bool {
	b, err := json.MarshalIndent(trigger, "", "  ")
	if err != nil {
		log.Printf("Evaluating Sensor Trigger, but error marshalling trigger: %v", err)
	} else {
		log.Printf("Evaluating Sensor Trigger: %s", b)
	}
	// TODO: Add sensor evaluation logic here.
	return false
}

// evaluateTriggers is used for non-scheduled (device-based) triggers.
// It iterates through device-based triggers (ignoring scheduled ones)
// and combines their results. If more than one trigger is defined, the optional
// ConditionOperator field ("and" or "or") is used to combine the booleans.
func evaluateTriggers(triggers []Trigger, payload map[string]interface{}) bool {
	var result bool
	for i, trigger := range triggers {
		var current bool
		switch strings.ToLower(trigger.Type) {
		case "single_device":
			current = validateSingleDeviceTrigger(trigger, payload)
		case "two_device_diff":
			current = handleTwoDeviceCompareTrigger(trigger, payload)
		// Skip scheduled triggers for device-based evaluation.
		case "scheduled":
			current = false
		default:
			log.Printf("Unknown trigger type in device automation: %s", trigger.Type)
			current = false
		}
		// For the first trigger, simply assign.
		if i == 0 {
			result = current
		} else {
			// If the trigger has a ConditionOperator, combine the result accordingly.
			op := "and"
			if trigger.ConditionOperator != nil {
				op = strings.ToLower(*trigger.ConditionOperator)
			}
			if op == "and" {
				result = result && current
			} else if op == "or" {
				result = result || current
			} else {
				log.Printf("Unknown condition operator '%s'; defaulting to AND", op)
				result = result && current
			}
		}
	}
	return result
}

func mapTimezoneOffset(tz string) int {
	mapping := map[string]int{
		// Eastern Time Zone
		"America/New_York":    -5,
		"America/Detroit":     -5,
		"America/Toronto":     -5,
		"America/Montreal":    -5,
		"America/Nipigon":     -5,
		"America/Thunder_Bay": -5,
		// Central Time Zone
		"America/Chicago":             -6,
		"America/Winnipeg":            -6,
		"America/Regina":              -6,
		"America/Indiana/Indianapolis": -5,
		"America/Indiana/Marengo":     -5,
		"America/Indiana/Petersburg":  -5,
		"America/Indiana/Tell_City":   -6,
		"America/Indiana/Vevay":       -5,
		"America/Indiana/Vincennes":   -5,
		"America/Indiana/Winamac":     -5,
		"America/Indiana/Knox":        -6,
		// Mountain Time Zone
		"America/Denver":   -6,
		"America/Edmonton": -6,
		"America/Phoenix":  -7,
		// Pacific Time Zone
		"America/Los_Angeles": -8,
		"America/Vancouver":   -8,
		"America/Whitehorse":  -8,
		// Alaska
		"America/Anchorage": -9,
		// Hawaii-Aleutian Time Zone
		"America/Adak": -10,
		// Atlantic Time Zone (Canada)
		"America/Halifax": -4,
		// Newfoundland (approximation)
		"America/St_Johns": -3,
	}
	if offset, ok := mapping[tz]; ok {
		return offset
	}
	return 0 // default to UTC if not mapped
}

// evaluateScheduledTrigger checks if the scheduled trigger should fire.
func evaluateScheduledTrigger(automation Automation, trigger Trigger) bool {
	// Calculate timezone offset and create a fixed zone
	offsetHours := mapTimezoneOffset(automation.Timezone)
	loc := time.FixedZone(automation.Timezone, offsetHours*3600)

	// Get the current time in the fixed timezone
	localNow := time.Now().In(loc)
	log.Printf("DEBUG: Current local time in %s: %s", automation.Timezone, localNow.Format("15:04:05"))

	// Log current day and scheduled days from trigger
	currentDay := localNow.Weekday().String()
	log.Printf("DEBUG: Current day: %s, Trigger days: %v", currentDay, trigger.DaysOfWeek)

	// Check if today's day is one of the trigger days
	found := false
	for _, day := range trigger.DaysOfWeek {
		if strings.EqualFold(day, currentDay) {
			found = true
			break
		}
	}
	if !found {
		log.Printf("DEBUG: Today (%s) is not in the scheduled days %v", currentDay, trigger.DaysOfWeek)
		return false
	}

	// Ensure a common_time is specified
	if trigger.CommonTime == nil {
		log.Printf("DEBUG: No common_time specified in trigger")
		return false
	}
	commonTimeStr := *trigger.CommonTime
	commonTime, err := time.Parse("15:04", commonTimeStr)
	if err != nil {
		log.Printf("DEBUG: Error parsing common_time '%s': %v", commonTimeStr, err)
		return false
	}

	// Build the scheduled time for today using the parsed common time
	scheduledTime := time.Date(localNow.Year(), localNow.Month(), localNow.Day(), commonTime.Hour(), commonTime.Minute(), 0, 0, loc)
	log.Printf("DEBUG: Scheduled time: %s", scheduledTime.Format("15:04:05"))

	// Set tolerance and compute difference
	tolerance := 3 * time.Minute
	diff := localNow.Sub(scheduledTime)
	if diff < 0 {
		diff = -diff
	}
	log.Printf("DEBUG: Time difference: %v, Tolerance: %v", diff, tolerance)
	if diff > tolerance {
		log.Printf("DEBUG: Current time (%s) is not within tolerance of scheduled time (%s)", localNow.Format("15:04:05"), scheduledTime.Format("15:04:05"))
		return false
	}

	// If automation has been executed before, check the delta
	if automation.LastExecuted != nil {
		lastExec := automation.LastExecuted.In(loc)
		log.Printf("DEBUG: Last executed time: %s", lastExec.Format("15:04:05"))
		delta := localNow.Sub(lastExec)
		log.Printf("DEBUG: Time since last execution: %v", delta)
		if delta < 5*time.Minute {
			log.Printf("DEBUG: Automation executed too recently; delta %v is less than threshold 3m", delta)
			return false
		}
	}

	return true
}

func scheduleHandler() {
	ticker := time.NewTicker(1 * time.Minute)
	defer ticker.Stop()
	for range ticker.C {
		log.Println("Scheduled Handler: Checking for scheduled automations...")
		var automations []Automation
		err := supabaseClient.DB.From("user_automations").
			Select("*").
			Eq("action_type", "scheduled").
			Execute(&automations)
		if err != nil {
			log.Printf("❌ Error fetching scheduled automations: %v", err)
			continue
		}
		log.Printf("✅ Found %d scheduled automations", len(automations))
		for _, automation := range automations {
			b, err := json.MarshalIndent(automation, "", "  ")
			if err != nil {
				log.Printf("Error marshalling automation: %v", err)
			} else {
				log.Printf("🕛 Processing scheduled automation: %s", b)
			}
			for _, trigger := range automation.Triggers {
				if trigger.Type == "scheduled" {
					if evaluateScheduledTrigger(automation, trigger) {
						updateAutomationLastExecuted(automation.ID, time.Now().UTC())
						log.Printf("Executing scheduled automation: %s", automation.ID)
						executeActions(automation.Actions, automation.UserID)
						break
					}
				}
			}
		}
	}
}

// sendPushNotificationForUser queries the notifications table and sends a push notification using the Expo SDK.
func sendPushNotificationForUser(userID, title, message string, data map[string]string) error {
	var notifications []struct {
		ExpoPushToken string `json:"expo_push_token"`
	}
	err := supabaseClient.DB.From("notifications").
		Select("expo_push_token").
		Eq("user_id", userID).
		Execute(&notifications)
	if err != nil {
		log.Printf("Error querying notifications for user %s: %v", userID, err)
		return err
	}
	if len(notifications) == 0 {
		log.Printf("No push tokens found for user %s", userID)
		return nil
	}
	for _, notif := range notifications {
		token := notif.ExpoPushToken
		if !strings.HasPrefix(token, "ExponentPushToken[") {
			token = fmt.Sprintf("ExponentPushToken[%s]", token)
		}
		pushToken, err := expo.NewExponentPushToken(token)
		if err != nil {
			log.Printf("Invalid push token %s: %v", token, err)
			continue
		}
		pushMessage := expo.PushMessage{
			To:       []expo.ExponentPushToken{pushToken},
			Title:    title,
			Body:     message,
			Sound:    "default",
			Data:     data,
			Priority: expo.DefaultPriority,
		}
		client := expo.NewPushClient(nil)
		resp, err := client.Publish(&pushMessage)
		if err != nil {
			log.Printf("Error sending push notification to token %s: %v", token, err)
			continue
		}
		if resp.ValidateResponse() != nil {
			log.Printf("Push notification to %s failed: %+v", token, resp)
		} else {
			log.Printf("Push notification sent successfully to %s, response: %+v", token, resp)
		}
	}
	return nil
}

// validateSingleDeviceTrigger checks a "single_device" trigger against the device payload.
func validateSingleDeviceTrigger(trigger Trigger, payload map[string]interface{}) bool {
	// (Optional) Check that the payload comes from the expected device.
	if trigger.DeviceID != nil && *trigger.DeviceID != "" {
		payloadDeviceID, ok := payload["device_id"].(string)
		if !ok || payloadDeviceID != *trigger.DeviceID {
			log.Printf("Single device trigger: payload device (%s) does not match trigger device (%s)", payloadDeviceID, *trigger.DeviceID)
			return false
		}
	}

	// Determine which metric to check.
	if trigger.Metric == nil {
		log.Println("Single device trigger: no metric specified")
		return false
	}
	metric := strings.ToLower(*trigger.Metric)
	var sensorKey string
	switch metric {
	case "temp":
		sensorKey = "temp_sensor_reading"
	case "humidity":
		sensorKey = "humid_sensor_reading"
	default:
		log.Printf("Single device trigger: unknown metric %s", metric)
		return false
	}

	// Get the sensor value from the payload.
	sensorValue, ok := getFloatFromPayload(payload, sensorKey)
	if !ok {
		log.Printf("Single device trigger: could not retrieve sensor value for key %s", sensorKey)
		return false
	}

	// Parse the trigger value (which is provided as a string).
	if trigger.Value == nil {
		log.Println("Single device trigger: no value specified")
		return false
	}
	triggerValue, err := strconv.ParseFloat(*trigger.Value, 64)
	if err != nil {
		log.Printf("Single device trigger: error parsing trigger value '%s': %v", *trigger.Value, err)
		return false
	}

	// Evaluate the condition.
	if trigger.Condition != nil {
		cond := strings.ToLower(*trigger.Condition)
		switch cond {
		case "gt":
			return sensorValue > triggerValue
		case "lt":
			return sensorValue < triggerValue
		case "eq":
			return sensorValue == triggerValue
		case "gte":
			return sensorValue >= triggerValue
		case "lte":
			return sensorValue <= triggerValue
		default:
			log.Printf("Single device trigger: unknown condition operator '%s'", cond)
			return false
		}
	}

	return false
}

// handleTwoDeviceCompareTrigger compares the reading from the device that sent the payload
// with the latest reading of the other device as stored in your Supabase table.
func handleTwoDeviceCompareTrigger(trigger Trigger, payload map[string]interface{}) bool {
    if trigger.Device1 == nil || trigger.Device2 == nil {
        log.Println("Two device trigger: Device1 or Device2 is nil")
        return false
    }

    payloadDeviceID, ok := payload["device_id"].(string)
    if !ok || payloadDeviceID == "" {
        log.Println("Two device trigger: payload missing device_id")
        return false
    }

    if trigger.Metric == nil {
        log.Println("Two device trigger: Metric field is nil")
        return false
    }

    metric := strings.ToLower(*trigger.Metric)
    var sensorKey string
    switch metric {
    case "temp":
        sensorKey = "temp_sensor_reading"
    case "humidity":
        sensorKey = "humid_sensor_reading"
    default:
        log.Printf("Two device trigger: unknown metric %s", metric)
        return false
    }

    var otherDeviceID string
    if trigger.Device1.DeviceID == payloadDeviceID {
        otherDeviceID = trigger.Device2.DeviceID
    } else if trigger.Device2.DeviceID == payloadDeviceID {
        otherDeviceID = trigger.Device1.DeviceID
    } else {
        log.Println("Two device trigger: Payload does not match Device1 or Device2")
        return false
    }

    // Get current sensor value
    currentValue, ok := getFloatFromPayload(payload, sensorKey)
    if !ok {
        log.Printf("Two device trigger: could not retrieve sensor value for %s", sensorKey)
        return false
    }

    // Fetch latest log from Supabase
    var logs []DeviceLog
    res := supabaseClient.DB.From("deviceLogs").Select("*").
        OrderBy("created_at", "desc").Limit(1).
        Eq("device_id", otherDeviceID).
        Execute(&logs)

    if res.Error() != "" || len(logs) == 0 {
        log.Printf("Two device trigger: failed to fetch latest log for device %s", otherDeviceID)
        return false
    }

    var otherValue float64
    switch metric {
    case "temp":
        if logs[0].TempSensorReading != nil {
            otherValue = *logs[0].TempSensorReading
        } else {
            log.Println("Two device trigger: Other device missing temp_sensor_reading")
            return false
        }
    case "humidity":
        if logs[0].HumidSensorReading != nil {
            otherValue = *logs[0].HumidSensorReading
        } else {
            log.Println("Two device trigger: Other device missing humid_sensor_reading")
            return false
        }
    default:
        log.Println("Two device trigger: Unexpected metric type")
        return false
    }

    // Compute absolute difference
    diff := currentValue - otherValue
    if diff < 0 {
        diff = -diff
    }

    // Parse trigger value
    if trigger.Value == nil {
        log.Println("Two device trigger: Trigger value is nil")
        return false
    }

    triggerValue, err := strconv.ParseFloat(*trigger.Value, 64)
    if err != nil {
        log.Printf("Two device trigger: Error parsing trigger value '%s': %v", *trigger.Value, err)
        return false
    }

    // Evaluate condition
    if trigger.Condition != nil {
        cond := strings.ToLower(*trigger.Condition)
        switch cond {
        case "gt":
            return diff > triggerValue
        case "lt":
            return diff < triggerValue
        case "eq":
            return diff == triggerValue
        case "gte":
            return diff >= triggerValue
        case "lte":
            return diff <= triggerValue
        default:
            log.Printf("Two device trigger: Unknown condition operator '%s'", cond)
            return false
        }
    }

    return false
}



func executeActions(actions []Action, userID string) {
	for _, action := range actions {
		switch action.Type {
		case "send_notification":
			log.Printf("Sending notification action: %s", action.Message)
			title := "Notification"
			msg := "You have a new notification."
			if action.Message != nil && *action.Message != "" {
				msg = *action.Message
			}
			// IMPORTANT: Replace "dummy-user-id" with the proper user ID from your context.
			data := map[string]string{"info": "extra data if needed"}
			err := sendPushNotificationForUser(userID, title, msg, data)
			if err != nil {
				log.Printf("Error sending notification for user %s: %v", userID, err)
			}
		case "turn_on_relay":
			log.Printf("Turning on relay for device: %s", action.DeviceID)
			// Implement relay logic here.
		default:
			log.Printf("Unknown action type: %s", action.Type)
		}
	}
}

func deviceAutomationHandler(task Task) {
	log.Printf("📡 Device Automation Handler: Processing message on topic %s", task.Topic)
	var payload map[string]interface{}
	if err := json.Unmarshal([]byte(task.Payload), &payload); err != nil {
		log.Printf("❌ Error parsing JSON payload: %v", err)
		return
	}
	log.Println("✅ Parsed Device Data:")
	for key, value := range payload {
		log.Printf("  %s: %v", key, value)
	}
	userID, ok := payload["user_id"].(string)
	if !ok || userID == "" {
		log.Println("❌ Missing or invalid user_id in payload. Skipping automation processing.")
		return
	}
	var automations []Automation
	err := supabaseClient.DB.From("user_automations").
		Select("*").
		Eq("user_id", userID).
		Execute(&automations)
	if err != nil {
		log.Printf("❌ Error fetching automations for user %s: %v", userID, err)
		return
	}
	log.Printf("📋 Found %d automations for user %s", len(automations), userID)
	for _, automation := range automations {
		b, err := json.MarshalIndent(automation, "", "  ")
		if err != nil {
			log.Printf("Error marshalling automation: %v", err)
		} else {
			log.Printf("Processing automation: %s", b)
		}
		// Note: we now pass the payload to evaluateTriggers.
		if evaluateTriggers(automation.Triggers, payload) {
			updateAutomationLastExecuted(automation.ID, time.Now().UTC())
			log.Printf("🚀 Executing automation: %s", automation.ID)
			executeActions(automation.Actions, automation.UserID)
		} else {
			log.Printf("❌ Automation %s did not meet trigger conditions", automation.ID)
		}
	}
}

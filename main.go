package main

import (
	"encoding/json"
	"errors"
	"fmt"
	"log"
	"net/http"
	"os"
	"os/signal"
	"strings"
	"sync"
	"syscall"
	"time"

	mqtt "github.com/eclipse/paho.mqtt.golang"
	"github.com/joho/godotenv"
	"github.com/nedpals/supabase-go"
)

// DeviceLog represents the structure of an device log entry
type DeviceLog struct {
	ID                 string     `json:"id"`                   // UUID, auto-generated by Supabase
	DeviceID           string     `json:"device_id"`            // UUID
	UserID             string     `json:"user_id"`              // UUID
	CreatedAt          time.Time  `json:"created_at"`           // Timestamp
	Status             string     `json:"status"`               // e.g., "online", "offline", "error"
	TempSensorReading  *float64   `json:"temp_sensor_reading"`  // Nullable
	HumidSensorReading *float64   `json:"humid_sensor_reading"` // Nullable
	RelayState         string     `json:"relay_state"`          // e.g., "on", "off", "idle"
	DeviceType         string     `json:"device_type"`          // "relay" or "sensor"
	Metadata           *string    `json:"metadata"`             // Optional JSON metadata
}

// Task structure to represent an MQTT message
type Task struct {
	Topic   string
	Payload string
}

// Automation represents the structure of an automation rule
type Automation struct {
	ID           string     `json:"id"`
	UserID       string     `json:"user_id"`
	Type         string     `json:"action_type"` // "triggered" or "scheduled"
	LastExecuted *time.Time `json:"last_executed,omitempty"`
	LastResult   *string    `json:"last_result,omitempty"`
	Triggers     []Trigger  `json:"triggers"`
	Actions      []Action   `json:"actions"`
	Timezone     string     `json:"timezone"`
	CreatedAt    time.Time  `json:"created_at"`
	UpdatedAt    time.Time  `json:"updated_at"`
}

// Trigger represents the structure of an automation trigger
type Trigger struct {
	Type              string   `json:"type"` // "scheduled", "single_device", "two_device_diff"
	Condition         *string  `json:"condition,omitempty"`
	CommonTime        *string  `json:"common_time,omitempty"`
	DaysOfWeek        []string `json:"days_of_week,omitempty"`
	ScheduleType      *string  `json:"schedule_type,omitempty"`
	ConditionOperator *string  `json:"conditionOperator,omitempty"`
	Value             *string  `json:"value,omitempty"`
	Metric            *string  `json:"metric,omitempty"`
	DeviceID          *string  `json:"device_id,omitempty"`
	BinID             *string  `json:"bin_id,omitempty"`
	LocationID        *string  `json:"location_id,omitempty"`
	Device1           *Device  `json:"device1,omitempty"`
	Device2           *Device  `json:"device2,omitempty"`
}

// Device represents a device in a two-device trigger
type Device struct {
	BinID      string `json:"bin_id"`
	DeviceID   string `json:"device_id"`
	LocationID string `json:"location_id"`
}

// Action represents the actions executed when an automation is triggered
type Action struct {
	Type     string  `json:"type"` // "send_notification", "turn_on_relay"
	Message  *string `json:"message,omitempty"`
	DeviceID *string `json:"device_id,omitempty"`
}

// Global variables
var (
	taskQueue         = make(chan Task, 1000) // Buffered channel to hold tasks
	maxWorkers        = 20                    // Maximum number of workers
	minWorkers        = 2                     // Minimum number of workers
	workerLock        sync.Mutex              // Mutex to protect workerCount
	activeWorkers     = make(map[int]chan bool)
	workerIDCounter   = 0
	supabaseClient    *supabase.Client
	wg                sync.WaitGroup
	gracefulShutdown  = make(chan os.Signal, 1) // Channel to capture OS signals
	once              sync.Once                 // Ensures Supabase client is initialized once
	defaultDeviceID   = "default-device-id"     // Default device_id for plain text payloads
	defaultDeviceType = "relay"                 // Default device_type for plain text payloads
)

var (
	mqttClientInstance mqtt.Client
	mqttOnce           sync.Once
)

func getMQTTClient() mqtt.Client {
	mqttOnce.Do(func() {
		broker := "tcp://mosquitto:1883"
		clientID := "guardian-daemon"

		opts := mqtt.NewClientOptions().
			AddBroker(broker).
			SetClientID(clientID).
			SetDefaultPublishHandler(messageHandler)

		client := mqtt.NewClient(opts)
		if token := client.Connect(); token.Wait() && token.Error() != nil {
			log.Fatalf("Failed to connect to MQTT broker: %v", token.Error())
		}
		log.Println("Connected to MQTT broker!")
		mqttClientInstance = client
	})
	return mqttClientInstance
}

func handleSendCommand(w http.ResponseWriter, r *http.Request) {
	// Handle CORS Preflight Request
	if r.Method == http.MethodOptions {
		w.Header().Set("Access-Control-Allow-Origin", "*")
		w.Header().Set("Access-Control-Allow-Methods", "POST, OPTIONS")
		w.Header().Set("Access-Control-Allow-Headers", "Content-Type")
		w.WriteHeader(http.StatusOK)
		return
	}

	// Set CORS headers
	w.Header().Set("Access-Control-Allow-Origin", "*")
	w.Header().Set("Access-Control-Allow-Methods", "POST")
	w.Header().Set("Access-Control-Allow-Headers", "Content-Type")
	w.Header().Set("Content-Type", "application/json")

	if r.Method != http.MethodPost {
		http.Error(w, "Invalid request method. Only POST is allowed.", http.StatusMethodNotAllowed)
		return
	}

	// Parse the incoming JSON
	var message struct {
		DeviceID string                 `json:"deviceId"`
		UserID   string                 `json:"userId"`
		Data     map[string]interface{} `json:"data"`
	}

	if err := json.NewDecoder(r.Body).Decode(&message); err != nil {
		log.Printf("Error decoding request body: %v", err)
		http.Error(w, "Invalid JSON format.", http.StatusBadRequest)
		return
	}
	defer r.Body.Close()

	// Validate required fields
	if message.DeviceID == "" || message.UserID == "" || message.Data == nil {
		http.Error(w, "Missing required fields: deviceId, userId, or data.", http.StatusBadRequest)
		return
	}

	// Serialize the Data object into a JSON string
	dataJSON, err := json.Marshal(message.Data)
	if err != nil {
		log.Printf("Error serializing data to JSON: %v", err)
		http.Error(w, "Failed to serialize data to JSON.", http.StatusInternalServerError)
		return
	}

	// Construct the MQTT topic
	topic := fmt.Sprintf("/toDevice/%s/%s", message.UserID, message.DeviceID)

	// Publish the message to MQTT
	client := getMQTTClient()
	token := client.Publish(topic, 0, false, dataJSON)
	token.Wait()

	if token.Error() != nil {
		log.Printf("Failed to publish MQTT message: %v", token.Error())
		http.Error(w, "Failed to publish MQTT message.", http.StatusInternalServerError)
		return
	}

	// Respond to the client
	response := map[string]string{
		"status":  "success",
		"topic":   topic,
		"message": fmt.Sprintf("Message successfully published to topic %s", topic),
	}
	json.NewEncoder(w).Encode(response)
}

// main function initializes the application
func main() {
	// Initialize Supabase client
	initSupabase()

	// Start dynamic scaling of workers
	go scheduleHandler()
	go monitorAndScaleWorkers()

	// Create the MQTT client
	client := getMQTTClient()

	// Connect to the MQTT broker
	if token := client.Subscribe("/toDaemon/#", 0, nil); token.Wait() && token.Error() != nil {
		log.Fatalf("Failed to subscribe to all topics: %v", token.Error())
	}
	log.Println("Subscribed to all topics!")

	// Handle graceful shutdown
	setupGracefulShutdown(client)

	// Init HTTP server
	http.HandleFunc("/sendComand", handleSendCommand)

	fmt.Println("Starting server on :5000...")
	err := http.ListenAndServe(":5000", nil)
	if err != nil {
		fmt.Println("Error starting server:", err)
	}

	// Keep the program running indefinitely
	select {}
}

// messageHandler handles incoming MQTT messages
func messageHandler(client mqtt.Client, msg mqtt.Message) {
	task := Task{
		Topic:   msg.Topic(),
		Payload: string(msg.Payload()),
	}

	select {
	case taskQueue <- task:
		log.Printf("Message enqueued: %s on topic %s", task.Payload, task.Topic)
		go deviceAutomationHandler(task)
	default:
		log.Printf("Task queue full. Dropping message: %s on topic %s", task.Payload, task.Topic)
	}
}

// initSupabase initializes the Supabase client as a singleton
func initSupabase() {
	once.Do(func() {
		// Load environment variables from .env file if present
		err := godotenv.Load()
		if err != nil {
			log.Println("Warning: .env file not found, falling back to system environment variables.")
		}

		supabaseURL := os.Getenv("SUPABASE_URL")
		supabaseKey := os.Getenv("SUPABASE_KEY")

		if supabaseURL == "" || supabaseKey == "" {
			log.Fatal("Supabase URL or Key not set in environment variables")
		}

		// Create Supabase client
		supabaseClient = supabase.CreateClient(supabaseURL, supabaseKey)
		log.Println("Connected to Supabase!")
	})
}

// worker processes tasks from the taskQueue
func worker(id int, stopWorkerCh chan bool) {
	log.Printf("Worker %d started", id)
	defer wg.Done()

	batch := []*DeviceLog{}
	batchSize := 10                  // Number of logs per batch
	batchInterval := 5 * time.Second // Time interval to flush batch
	ticker := time.NewTicker(batchInterval)
	defer ticker.Stop()

	for {
		select {
		case task := <-taskQueue:
			log.Printf("Worker %d processing task: %s on topic %s", id, task.Payload, task.Topic)
			deviceLog, err := parsePayload(task.Topic, task.Payload)
			if err != nil {
				log.Printf("Worker %d failed to parse payload: %v", id, err)
				continue
			}
			batch = append(batch, deviceLog)

			if len(batch) >= batchSize {
				err := batchInsertIntoSupabase(batch)
				if err != nil {
					log.Printf("Worker %d failed to batch insert: %v", id, err)
				} else {
					log.Printf("Worker %d successfully batch inserted %d tasks", id, len(batch))
				}
				batch = []*DeviceLog{} // Reset batch
			}

		case <-ticker.C:
			if len(batch) > 0 {
				err := batchInsertIntoSupabase(batch)
				if err != nil {
					log.Printf("Worker %d failed to batch insert: %v", id, err)
				} else {
					log.Printf("Worker %d successfully batch inserted %d tasks", id, len(batch))
				}
				batch = []*DeviceLog{} // Reset batch
			}

		case <-stopWorkerCh:
			log.Printf("Worker %d stopping", id)
			// Insert any remaining logs before exiting
			if len(batch) > 0 {
				err := batchInsertIntoSupabase(batch)
				if err != nil {
					log.Printf("Worker %d failed to batch insert during shutdown: %v", id, err)
				} else {
					log.Printf("Worker %d successfully batch inserted %d tasks during shutdown", id, len(batch))
				}
			}
			return
		}
	}
}

// parsePayload parses the MQTT payload and returns a DeviceLog struct
func parsePayload(topic, payload string) (*DeviceLog, error) {
	// Attempt to parse payload as JSON
	var rawData map[string]interface{}
	err := json.Unmarshal([]byte(payload), &rawData)
	if err != nil {
		// If payload is not JSON, insert dummy data
		log.Printf("Payload is not JSON: %s. Inserting dummy data.", payload)
		return createDummyDeviceLog(topic, payload), nil
	}

	// Helper function to extract string fields
	getString := func(key string) string {
		if val, exists := rawData[key]; exists {
			if str, ok := val.(string); ok {
				return str
			}
		}
		return "" // Default to empty string if not present or not a string
	}

	// Helper function to extract float fields
	getFloat := func(key string) *float64 {
		if val, exists := rawData[key]; exists {
			switch v := val.(type) {
			case float64:
				return &v
			case float32:
				f := float64(v)
				return &f
			case int:
				f := float64(v)
				return &f
			default:
				return nil
			}
		}
		return nil // Default to nil if not present or not a number
	}

	// Extract fields with defaults
	deviceID := getString("device_id")
	userID := getString("user_id")
	status := getString("status")
	deviceType := getString("device_type")
	relayState := getString("relay_state")

	tempReading := getFloat("temp_sensor_reading")
	humidReading := getFloat("humid_sensor_reading")

	// Optional metadata field
	var metadata *string
	if val, exists := rawData["metadata"]; exists {
		if str, ok := val.(string); ok {
			metadata = &str
		}
	}

	// Validate required fields
	if deviceID == "" || userID == "" || deviceType == "" {
		return nil, errors.New("missing required fields: device_id, user_id, or device_type")
	}

	// Create the DeviceLog struct
	deviceLog := &DeviceLog{
		DeviceID:           deviceID,
		UserID:             userID,
		CreatedAt:          time.Now(),
		Status:             status,
		TempSensorReading:  tempReading,
		HumidSensorReading: humidReading,
		RelayState:         relayState,
		DeviceType:         deviceType,
		Metadata:           metadata,
	}

	return deviceLog, nil
}

// createDummyDeviceLog creates a DeviceLog with dummy data
func createDummyDeviceLog(topic, payload string) *DeviceLog {
	// Extract user_id from topic
	// Assuming the topic format is "/gms/user/{user_id}/log"
	parts := strings.Split(topic, "/")
	userID := ""
	for i, part := range parts {
		if part == "user" && i+1 < len(parts) {
			userID = parts[i+1]
			break
		}
	}

	// If userID is not found, assign a default value
	if userID == "" {
		userID = "default-user-id"
	}

	// Assign a default device_id
	deviceID := defaultDeviceID

	// Assign default values for other fields
	status := payload               // Using the payload as status
	deviceType := defaultDeviceType // Defaulting to "relay"; adjust as needed
	relayState := "idle"            // Default relay state
	var metadata *string            // No metadata for dummy data

	return &DeviceLog{
		DeviceID:   deviceID,
		UserID:     userID,
		CreatedAt:  time.Now(),
		Status:     status,
		DeviceType: deviceType,
		RelayState: relayState,
		Metadata:   metadata,
		// Other fields remain nil or default
	}
}

// insertIntoSupabase inserts a single DeviceLog into Supabase
func insertIntoSupabase(deviceLog *DeviceLog) error {
	// Convert DeviceLog to a map for insertion
	data := map[string]interface{}{
		"device_id":            deviceLog.DeviceID,
		"user_id":              deviceLog.UserID,
		"created_at":           deviceLog.CreatedAt.Format(time.RFC3339),
		"status":               deviceLog.Status,
		"temp_sensor_reading":  deviceLog.TempSensorReading,
		"humid_sensor_reading": deviceLog.HumidSensorReading,
		"relay_state":          deviceLog.RelayState,
		"device_type":          deviceLog.DeviceType,
		"metadata":             deviceLog.Metadata,
	}

	// Insert the record
	returnData := supabaseClient.DB.From("deviceLogs").Insert(data).Execute(data)

	// Log the response for debugging
	log.Printf("Supabase Insert Response: %+v", returnData)

	return nil
}

// batchInsertIntoSupabase inserts multiple DeviceLogs into Supabase in a single batch
func batchInsertIntoSupabase(deviceLogs []*DeviceLog) error {
	// Convert DeviceLogs to a slice of maps
	var data []map[string]interface{}
	for _, logEntry := range deviceLogs {
		data = append(data, map[string]interface{}{
			"device_id":            logEntry.DeviceID,
			"user_id":              logEntry.UserID,
			"created_at":           logEntry.CreatedAt.Format(time.RFC3339),
			"status":               logEntry.Status,
			"temp_sensor_reading":  logEntry.TempSensorReading,
			"humid_sensor_reading": logEntry.HumidSensorReading,
			"relay_state":          logEntry.RelayState,
			"device_type":          logEntry.DeviceType,
			"metadata":             logEntry.Metadata,
		})
	}

	// Insert the records
	returnData := supabaseClient.DB.From("deviceLogs").Insert(data).Execute(data)

	// Log the response for debugging
	log.Printf("Supabase Batch Insert Response: %+v", returnData)

	return nil
}

const (
	workerScaleThreshold   = 0.8 // 80% of maxWorkers
	queueOverloadThreshold = 0.8 // 80% of queue capacity
)

// monitorAndScaleWorkers dynamically scales the number of workers based on the taskQueue size
func monitorAndScaleWorkers() {
	for {
		queueSize := len(taskQueue)
		currentWorkers := len(activeWorkers)
		workerCapacity := float64(maxWorkers) * workerScaleThreshold
		queueCapacity := float64(cap(taskQueue)) * queueOverloadThreshold

		workerLock.Lock()

		// Log if worker count exceeds threshold
		if float64(currentWorkers) > workerCapacity {
			log.Printf("⚠️ WARNING: Worker pool is at %.0f%% capacity (%d/%d workers in use).", (float64(currentWorkers)/float64(maxWorkers))*100, currentWorkers, maxWorkers)
		}

		// Log if worker count hits max capacity
		if currentWorkers >= maxWorkers {
			log.Printf("🚨 ALERT: Worker pool has reached max capacity (%d/%d workers). Incoming tasks may experience delays.", currentWorkers, maxWorkers)
		}

		// Scale up workers if needed
		if queueSize > currentWorkers && currentWorkers < maxWorkers {
			workerIDCounter++
			newWorkerID := workerIDCounter
			stopWorkerCh := make(chan bool)
			activeWorkers[newWorkerID] = stopWorkerCh
			wg.Add(1)
			go worker(newWorkerID, stopWorkerCh)
			log.Printf("🔼 Scaled up: Started worker %d. Total workers: %d", newWorkerID, len(activeWorkers))
		}

		// Scale down workers if queue is small and above minWorkers
		if queueSize < len(activeWorkers) && len(activeWorkers) > minWorkers {
			for workerID, stopCh := range activeWorkers {
				if len(activeWorkers) > minWorkers {
					close(stopCh)
					delete(activeWorkers, workerID)
					log.Printf("🔽 Scaled down: Stopped worker %d. Total workers: %d", workerID, len(activeWorkers))
					break
				}
			}
		}

		// Log if queue is nearing capacity
		if float64(queueSize) > queueCapacity {
			log.Printf("⚠️ WARNING: Task queue is at %.0f%% capacity (%d/%d tasks in queue).", (float64(queueSize)/float64(cap(taskQueue)))*100, queueSize, cap(taskQueue))
		}

		// Log if the queue is full
		if queueSize == cap(taskQueue) {
			log.Printf("🚨 ALERT: Task queue is FULL (%d tasks). Incoming messages may be dropped.", queueSize)
		}

		workerLock.Unlock()
		time.Sleep(2 * time.Second) // Adjust scaling interval as needed
	}
}

// setupGracefulShutdown handles termination signals to shut down workers gracefully
func setupGracefulShutdown(client mqtt.Client) {
	signal.Notify(gracefulShutdown, syscall.SIGINT, syscall.SIGTERM)

	go func() {
		sig := <-gracefulShutdown
		log.Printf("Received signal: %v. Initiating shutdown...", sig)

		// Disconnect MQTT client
		client.Disconnect(250)
		log.Println("Disconnected from MQTT broker.")

		// Stop all active workers
		workerLock.Lock()
		for workerID, stopCh := range activeWorkers {
			close(stopCh)
			log.Printf("Stopped worker %d", workerID)
		}
		workerLock.Unlock()

		// Wait for all workers to finish
		wg.Wait()
		log.Println("All workers have been stopped.")

		os.Exit(0)
	}()
}

// updateAutomationLastExecuted updates the automation record's last_executed field in Supabase.
func updateAutomationLastExecuted(automationID string, ts time.Time) error {
	data := map[string]interface{}{
		"last_executed": ts.Format(time.RFC3339),
	}
	res := supabaseClient.DB.From("user_automations").Update(data).Eq("id", automationID).Execute(data)
	if res.Error() != "" { // Call the function
		errStr := res.Error() // get the error string
		log.Printf("Error updating automation %s: %v", automationID, errStr)
		return errors.New(errStr)
	}
	log.Printf("Updated automation %s with last_executed %s", automationID, ts.Format(time.RFC3339))
	return nil
}

// evaluateSensorTrigger evaluates a sensor-based trigger.
// For demonstration, this function logs the trigger details and returns false.
// In a real implementation, you would add the logic to evaluate sensor conditions.
func evaluateSensorTrigger(trigger Trigger) bool {
	b, err := json.MarshalIndent(trigger, "", "  ")
	if err != nil {
		log.Printf("Evaluating Sensor Trigger, but error marshalling trigger: %v", err)
	} else {
		log.Printf("Evaluating Sensor Trigger: %s", b)
	}
	// TODO: Add sensor evaluation logic here.
	return false
}

// evaluateTriggers is used for non-scheduled (device-based) triggers.
// It iterates over the triggers and evaluates, for example, sensor-based triggers.
func evaluateTriggers(triggers []Trigger) bool {
	for _, trigger := range triggers {
		switch trigger.Type {
		case "Sensor":
			if evaluateSensorTrigger(trigger) {
				return true
			}
		default:
			log.Printf("Unknown or unhandled trigger type in device automation: %s", trigger.Type)
		}
	}
	return false
}

func mapTimezoneOffset(tz string) int {
	mapping := map[string]int{
		// Eastern Time Zone
		"America/New_York":    -5,
		"America/Detroit":     -5,
		"America/Toronto":     -5,
		"America/Montreal":    -5,
		"America/Nipigon":     -5,
		"America/Thunder_Bay": -5,
		// Central Time Zone
		"America/Chicago":             -6,
		"America/Winnipeg":            -6,
		"America/Regina":              -6, // Note: Regina does not observe DST.
		"America/Indiana/Indianapolis": -5, // Most of Indiana uses Eastern time.
		"America/Indiana/Marengo":     -5,
		"America/Indiana/Petersburg":  -5,
		"America/Indiana/Tell_City":   -6,
		"America/Indiana/Vevay":       -5,
		"America/Indiana/Vincennes":   -5,
		"America/Indiana/Winamac":     -5,
		"America/Indiana/Knox":        -6,
		// Mountain Time Zone
		"America/Denver":   -6,
		"America/Edmonton": -6,
		"America/Phoenix":  -7, // Arizona does not use DST.
		// Pacific Time Zone
		"America/Los_Angeles": -8,
		"America/Vancouver":   -8,
		"America/Whitehorse":  -8,
		// Alaska
		"America/Anchorage": -9,
		// Hawaii-Aleutian Time Zone
		"America/Adak": -10,
		// Atlantic Time Zone (Canada)
		"America/Halifax": -4,
		// Newfoundland (approximation)
		"America/St_Johns": -3, // Actually -3.5; approximated here as -3.
	}
	if offset, ok := mapping[tz]; ok {
		return offset
	}
	return 0 // default to UTC if not mapped
}

// evaluateScheduledTrigger checks if the scheduled trigger should fire.
// It verifies:
//  1. Today is one of the trigger's days_of_week (using the automation's fixed timezone).
//  2. The current time (in the automation's timezone) is within a tolerance of the trigger's common_time.
//  3. The automation has not been executed too recently (within 5 minutes).
func evaluateScheduledTrigger(automation Automation, trigger Trigger) bool {
	// Get the offset (in hours) for the automation's timezone.
	offsetHours := mapTimezoneOffset(automation.Timezone)
	// Create a fixed time zone using the offset.
	loc := time.FixedZone(automation.Timezone, offsetHours*3600)

	// Print out the local time in the automation's timezone.
	log.Printf("Local time in %s is %s", automation.Timezone, time.Now().In(loc).Format("15:04"))

	// Get the current time in the fixed zone.
	now := time.Now().In(loc)
	currentDay := now.Weekday().String() // e.g. "Monday"

	// Check if today is in the trigger's days_of_week.
	found := false
	for _, day := range trigger.DaysOfWeek {
		if strings.EqualFold(day, currentDay) {
			found = true
			break
		}
	}
	if !found {
		log.Printf("Today (%s) is not in the scheduled days %v", currentDay, trigger.DaysOfWeek)
		return false
	}

	// Ensure common_time is specified.
	if trigger.CommonTime == nil {
		log.Printf("No common_time specified in trigger")
		return false
	}
	commonTimeStr := *trigger.CommonTime
	// Parse common_time (expected format "15:04").
	commonTime, err := time.Parse("15:04", commonTimeStr)
	if err != nil {
		log.Printf("Error parsing common_time %s: %v", commonTimeStr, err)
		return false
	}
	// Create a time.Time for today using the hour and minute from common_time.
	scheduledTime := time.Date(now.Year(), now.Month(), now.Day(), commonTime.Hour(), commonTime.Minute(), 0, 0, loc)

	// Set tolerance to 3 minutes.
	tolerance := 3 * time.Minute
	diff := now.Sub(scheduledTime)
	if diff < 0 {
		diff = -diff
	}
	if diff > tolerance {
		log.Printf("Current time (%s) is not within tolerance of scheduled time (%s)", now.Format("15:04"), scheduledTime.Format("15:04"))
		return false
	}

	// Check if automation was executed too recently (within 3 minutes).
	if automation.LastExecuted != nil {
		lastExec := automation.LastExecuted.In(loc)
		if now.Sub(lastExec) < 3*time.Minute {
			log.Printf("Automation executed recently at %s", lastExec.Format("15:04"))
			return false
		}
	}

	// All checks passed.
	return true
}

func scheduleHandler() {
	ticker := time.NewTicker(1 * time.Minute) // Runs every 60 seconds
	defer ticker.Stop()

	for range ticker.C {
		log.Println("Scheduled Handler: Checking for scheduled automations...")

		// Query Supabase for scheduled automations
		var automations []Automation
		err := supabaseClient.DB.From("user_automations").
			Select("*").
			Eq("action_type", "scheduled").
			Execute(&automations)
		if err != nil {
			log.Printf("❌ Error fetching scheduled automations: %v", err)
			continue
		}

		log.Printf("✅ Found %d scheduled automations", len(automations))

		// Process each automation
		for _, automation := range automations {
			// Log full automation object as JSON
			b, err := json.MarshalIndent(automation, "", "  ")
			if err != nil {
				log.Printf("Error marshalling automation: %v", err)
			} else {
				log.Printf("🕛 Processing scheduled automation: %s", b)
			}
			// For each scheduled trigger in the automation, check if it should fire.
			for _, trigger := range automation.Triggers {
				if trigger.Type == "scheduled" {
					if evaluateScheduledTrigger(automation, trigger) {
						// Update the automation's last_executed field before executing actions.
						updateAutomationLastExecuted(automation.ID, time.Now().UTC())
						log.Printf("Executing scheduled automation: %s", automation.ID)
						executeActions(automation.Actions)
						break // Execute once per automation.
					}
				}
			}
		}
	}
}

func executeActions(actions []Action) {
	for _, action := range actions {
		switch action.Type {
		case "send_notification":
			log.Printf("Sending notification: %s", action.Message)
			// Implement notification logic
		case "turn_on_relay":
			log.Printf("Turning on relay for device: %s", action.DeviceID)
			// Implement relay logic
		default:
			log.Printf("Unknown action type: %s", action.Type)
		}
	}
}

func deviceAutomationHandler(task Task) {
	log.Printf("📡 Device Automation Handler: Processing message on topic %s", task.Topic)

	// Declare a variable to hold the dynamic JSON payload
	var payload map[string]interface{}

	// Attempt to unmarshal the JSON payload
	err := json.Unmarshal([]byte(task.Payload), &payload)
	if err != nil {
		log.Printf("❌ Error parsing JSON payload: %v", err)
		return
	}

	// Print the extracted data
	log.Println("✅ Parsed Device Data:")
	for key, value := range payload {
		log.Printf("  %s: %v", key, value)
	}

	// Extract `user_id` from the payload
	userID, ok := payload["user_id"].(string)
	if !ok || userID == "" {
		log.Println("❌ Missing or invalid user_id in payload. Skipping automation processing.")
		return
	}

	// Query Supabase for automations for this specific user
	var automations []Automation
	err = supabaseClient.DB.From("user_automations").
		Select("*").
		Eq("user_id", userID). // Fetch only automations for this user
		Execute(&automations)

	if err != nil {
		log.Printf("❌ Error fetching automations for user %s: %v", userID, err)
		return
	}

	log.Printf("📋 Found %d automations for user %s", len(automations), userID)

	// Process each automation
	for _, automation := range automations {
		// Log full automation object as JSON
		b, err := json.MarshalIndent(automation, "", "  ")
		if err != nil {
			log.Printf("Error marshalling automation: %v", err)
		} else {
			log.Printf("Processing automation: %s", b)
		}

		// For device-based triggers, use the existing evaluation logic.
		if evaluateTriggers(automation.Triggers) {
			// Update the automation's last_executed field before executing actions.
			updateAutomationLastExecuted(automation.ID, time.Now().UTC())
			log.Printf("🚀 Executing automation: %s", automation.ID)
			executeActions(automation.Actions)
		} else {
			log.Printf("❌ Automation %s did not meet trigger conditions", automation.ID)
		}
	}
}
